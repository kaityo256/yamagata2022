# モンテカルロ法(1)基礎的な話題

* 乱数とはなにか
* モンテカルロ法
* マルコフ連鎖モンテカルロ法とメトロポリス法
* エラーバーについて

## はじめに

モンテカルロ法とは、乱数を使って何かを評価する方法です。一般には単純なモンテカルロ法が使われることは稀で、ほとんどの場合「モンテカルロ法」と言うとマルコフ連鎖モンテカルロ法のことを指します。モンテカルロ法の原理は非常に単純であり、コードも比較的容易です。しかし、その本質の理解はかなり難しいものです。以下では、乱数の説明からはじめ、モンテカルロ法とはなにか、なぜ必要なのか、何が難しいのかをなるべく平易に説明しようと思います。

## 乱数とはなにか？

まずは乱数を定義しましょう。何か数列$r_i$があるとします。$r_0$から$r_i$まで既知である時、$r_{i+1}$を全く予想できない時、この数列を**乱数列(random sequence)**、乱数列のそれぞれの要素を**乱数(random number)**と呼びます。簡単な例はサイコロです。$i$回目に振った時のサイコロの目を$r_i$としましょう。この時、$r_i$は1から6までのどれかの値を取ります。さて、いま5回サイコロを振って、「1,5,3,2,2,2」という目が出たとしましょう。この時、7回目のサイコロの目$r_7$を予想できるでしょうか？イカサマの無いサイコロであれば、$r_7$が取る値は1から6まで等確率であり、これまでの履歴に依りません。このように、過去の履歴から次の値が全く予想できないので、「サイコロを振ってでてきた目の履歴」は乱数列とみなせます。

乱数はコンピュータでよく使われています。例えばゲームでは乱数は欠かせません。ソシャゲのガチャや、RPGの「会心の一撃」、ポケットモンスターの個体差などに乱数が使われています。コンピュータで使われる乱数は、これまでの履歴から次の数を作っているため、原理的には次の数が予想可能です。このような乱数を**疑似乱数(pseudo random number)**と呼びます。数値計算で使う乱数は疑似乱数なので、単に乱数と言うと疑似乱数のことを指します。

一方、真の意味で次の数が予想できない「本当の乱数」を「真乱数」と呼びます。新乱数は、熱雑音や、放射性物質の崩壊など、物理現象を利用して生成します。このような装置を物理乱数生成器と呼びます。サイコロも一種の物理乱数生成器と言えます。一部のCPUには、物理乱数生成器を搭載しているものもあります(例えばIntelのrdrandなど)。

疑似乱数は、一見すると乱数に見えますが、周期性があったり、十分に長い履歴を知ると次の値が予想できたりするため、たとえばセキュリティ目的などに使う場合は注意が必要です。しかし、数値計算で使う乱数は

* 十分に周期性が長い(相関がほとんど無い)
* 出現する数に偏りがない(一様性)

さえ満たされていれば、予測可能であっても問題ありません。逆に、同じ乱数の種からは同じ乱数列が生成されることを積極的に利用し、乱数を使ったコードのデバッグを行ったりします。疑似乱数を生成するアルゴリズムはいろいろありますが、現在広く使われているのはメルセンヌ・ツイスター法です。ほとんどのプログラミング言語において、乱数を生成する関数のデフォルトに選ばれています。一方、Xorshift法という、極めて高速に動作し、乱数の性質も(メルセンヌ・ツイスターには及ばないものの)非常に良い手法も提案されており、Google ChromeのJavaScriptの乱数生成関数`Math.random()`に採用されています。

疑似乱数生成アルゴリズムについては詳しくは触れませんが、その性質と使い方だけ簡単に見ておきましょう。Pythonで乱数を使うには`random`を`import`してから`random.random()`を呼び出します。これは、呼び出すたびに異なる0から1までの浮動小数点数を返す関数です。

```py
import random
for _ in range(5):
    print(random.random())
```

実行するたびに異なる値が表示されます。

```sh
$ python3 rand.py
0.7183142085184294
0.625356371754038
0.8206028825940407
0.5122008096362916
0.7253633754087734

$ python3 rand.py
0.3618195051209263
0.7496549080606681
0.3396919019733251
0.9722928645993307
0.3532634875426808
```

しかし、「乱数の種」を指定すると、何度実行しても同じ数列が表示されます。

```py
import random
random.seed(1)
for _ in range(5):
    print(random.random())
```

```sh
$ python3 rand.py
0.13436424411240122
0.8474337369372327
0.763774618976614
0.2550690257394217
0.49543508709194095

$ pyton3 rand.py
0.13436424411240122
0.8474337369372327
0.763774618976614
0.2550690257394217
0.49543508709194095
```

疑似乱数生成は、これまでの履歴をうまいこと使って次の数を作るアルゴリズムです。最初の「種」が同じならば、履歴が同じになり、必ず同じ数列が得られます。Pythonで種を指定しなかった場合に毎回異なる数列が得られたのは、種を指定しなかった場合にシステム時刻が指定されるからです。

一方、C++では、乱数の種を指定しなければ同じ種が使われるため、何度実行しても同じ結果になります。

```cpp
#include <iostream>
#include <random>

int main() {
  std::mt19937 mt;
  std::uniform_real_distribution<> ud(0.0, 1.0);
  for (int i = 0; i < 5; i++) {
    std::cout << ud(mt) << std::endl;
  }
}
```

```sh
$ g++ rand.cpp
$ ./a.out
0.135477
0.835009
0.968868
0.221034
0.308167

$ ./a.out
0.135477
0.835009
0.968868
0.221034
0.308167
```

このように、乱数生成にい同じアルゴリズムを使っていても、異なる言語では異なる仕様になっていたりするので注意が必要です。

## モンテカルロ法

モンテカルロ法とは、乱数を使ってなにかの期待値を計算する手法の総称です。数値計算において、なにかの期待値を計算したいことがよくあります。しかし、興味ある系において期待値が厳密に計算できることはほとんどないため、乱数を使ったサンプリングにより期待値を求めます。

モンテカルロ法の例としてよく出てくるのが「円周率の計算」です。0から1の間の一様乱数を$x$、$y$と二つ作り、その二乗和$x^2+y^2$が1より小さい確率を求めることで、それが$\pi/4$となることから円周率が求まります。

たとえばコードはこんな感じになるでしょう。

```py
import random

random.seed(1)
pi = 0.0
N = 1000000
for _ in range(N):
    x = random.random()
    y = random.random()
    if x**2 + y**2 < 1.0:
        pi = pi + 1.0
pi = pi/N*4
print(pi)
```

実行結果はこうなります。

```sh
$ python3 pi.py
3.14138
```

当然ですが、円周率は厳密に計算することはできません。しかし、サンプリングによりその近似値を推定することができます。この計算は、数式で表すなら以下の積分を実行していることに対応します。

$$
\frac{\pi}{4} = \int_0^1 \int_0^1 \Theta (1- x^2 + y^2) dx dy
$$

ここで$\Theta(x)$は、$x>0$なら$1$、$x<0$なら$0$となる関数(ヘヴィサイドの階段関数)です。先程のコードは、サンプリングによりこの積分値を評価していることに対応します。このように、モンテカルロ法は「式は書けるけれど、厳密に評価することが難しい和や積分」の評価に使われます。

さて、ここで使われた手法は単純サンプリングと呼ばれ、効率がよくありません。数値計算で使われるモンテカルロ法は、ほぼ「マルコフ連鎖モンテカルロ法」のことを指します。以下では、まず単純サンプリングで用語の説明をした後、マルコフ連鎖モンテカルロ法について説明します。

### 単純サンプリング

いま、普通のサイコロがあったとしましょう。1から6までの目が書いてあります。それぞれの目の出る確率が等しい時、サイコロの目の期待値はどれくらいでしょうか？答えはすぐに「3.5」だとわかりますが、後のためにもう少しきちんと議論しておきましょう。しばらく「当たり前」の議論が続きますが、我慢してついてきてください。

サイコロの目の状態に通し番号をつけ、$k$番目の状態の目の値を$Y_k$で表現します。$k$は1から6までで、$Y_k = k$です。状態$k$が出る確率を$p_k$としましょう。この時、サイコロの目の期待値$\bar{X}$は、以下のように表現できます。

$$
\bar{X} = \sum_{k=1}^6 Y_k p_k = \sum_{k=1}^6 k p_k
$$

公平なサイコロであれば、全ての目の出る確率が等しいため、$p_k$は$k$に寄らず$1/6$です。したがって、

$$
\bar{X} = \sum_{k=1}^6 \frac{k}{6} = 3.5
$$

と期待値が厳密に計算できます。さて、サイコロが公平でない、つまり出る目が偏っており、事前にどの目がどれくらい出るかわからないとしましょう。目として$k$が出る確率$p_k$が事前にわからない場合、まずはその確率を推定してやる必要があります。

まずは何度もサイコロを振って、$k$が出た回数を数えましょう。これを$w_k$とします。サイコロを振った回数の総数$N$は、$w_k$の和で表せます。

$$
N = \sum_k w_k
$$

そして、$k$が出る確率$p_k$は、$N$と$w_k$の比として推定できます。

$$
p_i \sim \frac{w_k}{N}
$$

以上から、サイコロの目の期待値は

$$
\bar{X} = \sum_k k p_k \sim \sum_k k \frac{w_k}{N}
$$

さて、サイコロを何度も振り、$i$回目に出た目が$\hat{X}_i$としましょう。サイコロを$N$回振って、出た目が$k$であった回数は以下のように書けます。

$$
w_k = \sum_{i=1}^N \delta_{\hat{X}_i, k}
$$

$\delta_{\mu,\nu}$はクロネッカーのデルタで、$\mu=\nu$の時に1、そうでなければ0となるものです。わざわざ式で書いていますが、サイコロの目が出た回数を数えているだけです。

さて、$w_k$を先の式に代入しましょう。

$$
\bar{X} \sim \sum_k k \frac{w_k}{N} =
\frac{1}{N} \sum_k k \sum_{i=1}^N \delta_{\hat{X}_i, k}
$$

和を入れ替えます。

$$
\sum_k k \sum_{i=1}^N \delta_{\hat{X}_i, k}
= \sum_{i=1}^N \sum_k k \delta_{\hat{X}_i, k}
$$

$k\delta_{\hat{X}_i, k}$は、$\hat{X}_i = k$の時にkに、それ以外は$0$ですから、$k$に関して和を取ると、単純に$\hat{X}_i$になります。

以上から、

$$
\hat{X} \sim \frac{1}{N} \sum_{i=1}^N \hat{X}_i
$$

を得ました。要するに何度もサイコロを振って、その平均を取りなさい、と言ってるだけです。ただ、

* 期待値とは、値の出現確率$p_k$に値$k$をかけたものの和である
* 出現確率$p_k$が事前にわからないのなら、出現頻度$w_k$を推定し、そこから出現確率$p_k$を推定する必要がある

ということに注意しましょう。ここで目として$k$が出る確率は$w_k$に比例しています。この$w_k$を「重み」と呼びます。事前に重みがわかれば、その総和と重みの比が出現確率を与えます。$w_k$の総和を$Z$とすると、

$$
Z = \sum_k w_k
$$

$$
p_k = \frac{w_k}{Z}
$$

となります。公平なサイコロの要件は、全ての目の出現重みが等しいことです。$w_k$は比だけが問題となるので、$w_k = 1$としましょう。すると、$Z=6$、$p_k = 1/6$となります。

普通のサイコロでは、全ての目が異なっていたため、$k$番目の状態の目の値$Y_k$は$k$に等しく、単に$k$で置き換えておしまいでした。次に、目に重複のあるサイコロを考えてみましょう。

6面に「1,2,2,3,3,3」と描かれたサイコロがあるとします。この6つの状態の出現頻度は等しいとしましょう。$k$番目の状態の目の値を$Y_k$とします。つまり、
$$
Y_1 = 1, Y_2 = 2, Y_3 = 2, Y_4 = 3,Y_5 = 3,Y_6 = 3
$$
です。すると、このサイコロの目の期待値は

$$
\bar{X} = \sum_{k=1}^6 Y_k p_k
$$

となります。しかし、状態は$k$種類ありますが、値は1,2,3の3種類しかありません。そこで、値によってまとめてしまった方が効率的です。いま、値$j$を取る状態の数を$g_j$としましょう。今回のケースでは$g_1 = 1, g_2 = 2, g_3 = 3$です。

すると、和を値で取りなおすことができます。値$j$を取る状態が現れる確率を$p_j$とすると、

$$
\bar{X} = \sum_{j=1}^3 j g_j p_j
$$

となります。もともとが公平なサイコロですから、値$j$に関わらず、状態が現れる確率は$1/6$です。したがって、$p_j=1/6$であり、期待値が厳密に計算できます。

ここまでの用語の整理をすると、

* 値$j$を持つ状態の出現確率が$p_j$であり、
* 値$j$を持つ状態の状態数が$g_j$個である時、
* 値の期待値は$\sum j g_j p_j$で書ける

という、至極当たり前のことを言っているだけです。

### 格子ガス模型

サイコロの例は簡単でした。もう少し興味ある物理現象の例として、気液相転移を考えましょう。相転移とは、温度等を変化させた時に、ミクロな性質は変わらないにも関わらず、マクロな性質が大きく変化することです。例えば、大気圧下において水は100度で沸騰して水蒸気になりますが、ミクロにみれば水分子の性質は全く変わっていません。水分子同士の相互作用は温度に依存しないと思われるのに、温度により固体、液体、気体と、全く振る舞いが異なる状態になります。

このうち、気体と液体の相転移を考えてみましょう。原子が近距離で斥力、中間距離で引力、遠距離で相互作用しないという条件を満たすと気体と液体の相転移がおきます。これを非常に単純化し、格子上に原子を置く格子ガス模型を考えましょう。

$V = L x L$の正方格子を考えます。この格子の上に$N$個の原子を起きます。「近距離で斥力」を表現すうため、原子は一つのサイトに一つしか置けないことにしましょう。また、「中間距離で引力」を表現するため、原子が上下左右に隣り合う場合は、$\epsilon$だけエネルギーが下がることにします。それ以外の原子は相互作用しません(遠距離で相互作用なしを表現)。

系の状態は数え上げが可能ですから、状態すべてに通し番号$i$をつけましょう。状態$i$のエネルギーを$E_i$とします。この状態の出現確率は、ボルツマン重み
$$
w_i = \exp(-E_i/kT)
$$
に比例するとしましょう。$k$はボルツマン定数、$T$は絶対温度です。これは、エネルギーが低い状態ほど出現しやすいことを表現しています。

状態$i$の出現確率$p_i$は、重み$w_i$の総和
$$
Z = \sum_i w_i
$$
を使って
$$
p_i = \frac{w_i}{Z}
$$
と書けます。すると、ある温度におけるエネルギーの期待値は
$$
U(T) = \sum_i E_i p_i
$$

と表すことができます。この$U(T)$を様々な温度$T$で計算するのが目的です。なんとなく、温度が低い時には偏った状態(液相)となってエネルギーが下がり、温度が高いと原子がバラバラな状態(気相)になってエネルギーが上がりそうな気がします。

さて、先程の和は状態番号に対して取られていましたが、

簡単のため、$N=2$としましょう。状態$i$において、二つの原子が隣り合っていれば$E_i=-\epsilon$、そうでなければ$E_i=0$です。
